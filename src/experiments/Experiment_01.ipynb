{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FItrSTctYoYX",
        "outputId": "f19d7dce-3db0-4efd-cff5-26947e93f034"
      },
      "outputs": [],
      "source": [
        "# 1) Mount Drive (run once)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfpOKUHmYh8g",
        "outputId": "29b0d524-68d3-4ff6-a80b-371f256751ae"
      },
      "outputs": [],
      "source": [
        "# Final Two-Pass Chunked Pipeline: Drop noise, Timestamp, constant cols, downsample benign, save reduced CSV\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------- USER CONFIG ----------\n",
        "file_path = \"/content/drive/MyDrive/AI_IDS_Graduation_Project/Dataset/All-Processed-Dataset-for-ML-Algorithms.csv\"\n",
        "output_file_csv = \"/content/drive/MyDrive/AI_IDS_Graduation_Project/Dataset/All-Processed-Reduced-Cleaned.csv\"\n",
        "chunk_size = 1_000_000             # adjust based on available RAM\n",
        "target_ratio = 4.2               # target benign:attacks ratio\n",
        "random_seed = 42\n",
        "# ---------------------------------\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(os.path.dirname(output_file_csv), exist_ok=True)\n",
        "\n",
        "# -------------------------\n",
        "# Pass 1: Count labels & detect constant columns\n",
        "# -------------------------\n",
        "print(\"Pass 1: counting labels and detecting constant columns...\")\n",
        "\n",
        "label_counts = {}\n",
        "constant_cols = None\n",
        "\n",
        "reader = pd.read_csv(file_path, chunksize=chunk_size, low_memory=False)\n",
        "for chunk in tqdm(reader, desc=\"Scanning chunks\"):\n",
        "    # normalize Label column: strip whitespace\n",
        "    chunk['Label'] = chunk['Label'].astype(str).str.strip()\n",
        "    \n",
        "    # drop noisy header rows\n",
        "    chunk = chunk.loc[chunk['Label'] != 'Label']\n",
        "\n",
        "    # drop Timestamp for constant column detection\n",
        "    if 'Timestamp' in chunk.columns:\n",
        "        chunk = chunk.drop(columns=['Timestamp'])\n",
        "\n",
        "    # update label counts\n",
        "    vc = chunk['Label'].value_counts()\n",
        "    for k, v in vc.items():\n",
        "        label_counts[k] = label_counts.get(k, 0) + int(v)\n",
        "\n",
        "    # detect constant columns\n",
        "    nunique = chunk.nunique(dropna=False)\n",
        "    if constant_cols is None:\n",
        "        constant_cols = set(nunique.index[nunique <= 1])\n",
        "    else:\n",
        "        constant_cols &= set(nunique.index[nunique <= 1])\n",
        "\n",
        "print(\"Label counts (sample):\")\n",
        "for k, v in sorted(label_counts.items(), key=lambda x: -x[1])[:20]:\n",
        "    print(f\"  {k}: {v:,}\")\n",
        "\n",
        "print(f\"\\nConstant columns detected ({len(constant_cols)}): {constant_cols}\")\n",
        "\n",
        "# Compute benign/attack counts\n",
        "total_benign = label_counts.get('Benign', 0)\n",
        "total_attacks = sum(v for k, v in label_counts.items() if k not in ('Benign','Label'))\n",
        "\n",
        "print(f\"\\nTotal benign: {total_benign:,}\")\n",
        "print(f\"Total attacks: {total_attacks:,}\")\n",
        "\n",
        "# Compute sampling fraction for benign rows\n",
        "if total_benign == 0:\n",
        "    raise ValueError(\"No 'Benign' rows found; check Label column spelling/casing.\")\n",
        "\n",
        "target_benign = int(total_attacks * target_ratio)\n",
        "sample_frac = min(1.0, target_benign / total_benign)\n",
        "\n",
        "print(f\"Target benign rows: {target_benign:,}\")\n",
        "print(f\"Sampling fraction for benign rows: {sample_frac:.4f} ({sample_frac*100:.2f}%)\")\n",
        "\n",
        "# -------------------------\n",
        "# Pass 2: Clean, downsample, and write reduced CSV\n",
        "# -------------------------\n",
        "if os.path.exists(output_file_csv):\n",
        "    print(\"Removing existing output_file_csv to avoid duplication.\")\n",
        "    os.remove(output_file_csv)\n",
        "\n",
        "write_header = True\n",
        "kept_counts = {\n",
        "    'benign_kept': 0,\n",
        "    'attacks_kept': 0,\n",
        "    'dropped_label_rows': 0,\n",
        "    'total_processed': 0\n",
        "}\n",
        "\n",
        "reader = pd.read_csv(file_path, chunksize=chunk_size, low_memory=False)\n",
        "rng = np.random.default_rng(random_seed)\n",
        "\n",
        "for chunk in tqdm(reader, desc=\"Pass 2: processing chunks\"):\n",
        "    chunk['Label'] = chunk['Label'].astype(str).str.strip()\n",
        "\n",
        "    # drop noisy header rows\n",
        "    mask_bad_label = chunk['Label'] == 'Label'\n",
        "    if mask_bad_label.any():\n",
        "        kept_counts['dropped_label_rows'] += int(mask_bad_label.sum())\n",
        "        chunk = chunk.loc[~mask_bad_label]\n",
        "\n",
        "    # drop Timestamp\n",
        "    if 'Timestamp' in chunk.columns:\n",
        "        chunk = chunk.drop(columns=['Timestamp'])\n",
        "\n",
        "    # drop constant columns\n",
        "    if constant_cols:\n",
        "        chunk = chunk.drop(columns=list(constant_cols), errors=\"ignore\")\n",
        "\n",
        "    # split benign vs attacks\n",
        "    mask_benign = chunk['Label'] == 'Benign'\n",
        "    benign_df = chunk.loc[mask_benign]\n",
        "    attack_df = chunk.loc[~mask_benign]\n",
        "\n",
        "    # sample benign rows\n",
        "    if sample_frac >= 1.0:\n",
        "        benign_sampled = benign_df\n",
        "    else:\n",
        "        benign_sampled = benign_df.sample(frac=sample_frac, random_state=random_seed)\n",
        "\n",
        "    # update counters\n",
        "    kept_counts['benign_kept'] += len(benign_sampled)\n",
        "    kept_counts['attacks_kept'] += len(attack_df)\n",
        "    kept_counts['total_processed'] += len(chunk)\n",
        "\n",
        "    # concat attacks + sampled benign and write to CSV\n",
        "    to_write = pd.concat([attack_df, benign_sampled], ignore_index=True)\n",
        "    to_write.to_csv(output_file_csv, mode='a', header=write_header, index=False)\n",
        "    write_header = False\n",
        "\n",
        "# -------------------------\n",
        "# Final summary\n",
        "# -------------------------\n",
        "print(\"\\nâœ… Done writing reduced & cleaned CSV:\")\n",
        "print(output_file_csv)\n",
        "\n",
        "print(\"\\nðŸ“Š Final summary:\")\n",
        "print(f\"  Benign kept:   {kept_counts['benign_kept']:,}\")\n",
        "print(f\"  Attacks kept:  {kept_counts['attacks_kept']:,}\")\n",
        "print(f\"  Dropped Label rows: {kept_counts['dropped_label_rows']:,}\")\n",
        "print(f\"  Total processed: {kept_counts['total_processed']:,}\")\n",
        "print(f\"  Final benign:attack ratio â‰ˆ {kept_counts['benign_kept'] / max(1, kept_counts['attacks_kept']):.2f} : 1\")\n",
        "print(f\"  Constant columns dropped: {constant_cols}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
